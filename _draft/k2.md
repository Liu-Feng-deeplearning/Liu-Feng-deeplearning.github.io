## Wenet + K2





### K2 核心算法简介

细节可以直接看[官网: k2算法简介](https://k2-fsa.github.io/k2/core_concepts/index.html)和对应[k2 源码](https://github.com/k2-fsa/k2)，这里只做简单的摘要:

(题外: 这个官网 document 格式排版相当精美，赏心悦目。)

总结几个核心要点
- Ragger Tensor(Array): 非规则二维序列表示，可以认为是一种稀疏矩阵的表示方法。是整个 k2 使用的核心数据结构。
- DenseMatrix to Fsa: Dense Fsa, 将神经网络输出概率矩阵转换成 fsa 的表示
- fsa auto Grad: 对 fsa 中两个基本操作的反向传播计算, 相当于对应传统 Discriminate-training 中的分子和分母，现在这两个量都可以求导了。 
    - Tropical semiring: it takes the max score of alternative paths.
    - Log semiring: it takes the log_add score of alternative paths.
- CtcLoss: 最重要的 api 接口函数，提供类似普通 CtcLoss 的用法。

#### DenseMatrix

假设神经网络输出维度为 [T X M], T 是时间方向上帧的数目， M是发音词典中对应token的个数。

那么，生成的 Fsa 图 由 T个状态构成，每个状态由m条边发射到下一状态。

#### CtcLoss in K2
思路也很清晰

- step1: intersect graph and dense fsa from nnet. 构建统一的解码图         
- step2: get_tot_scores, 计算所有路径的和

---  
### wenet(Transformer) + K2


### 准备工作与安装

k2 遵循官网的安装教程，直接 pip 安装即可。

安装过程中的两个注意点:
1. k2 对应 cuda 只能用10.1及以上版本。同时，可能会和 ubuntu 16 有冲突(GLIBC_2.27’ not found)，建议升级成 ubuntu 18.0
2. 默认 安装 k2 时，使用torch1.7。但在安装 torchaudio 时，默认使用 torch1.9 ，从而覆盖掉之前的版本，造成版本冲突。可以指定库版本从而对应相同的torch，例如
    ```text
    pip3 install torchaudio==0.7.2 
    ```

最终我们执行
```bash
python3 k2.version
```
没问题即可，k2 正式搞起！！

附：[Cuda10.1 安装地址](https://developer.nvidia.com/cuda-10.1-download-archive-update2?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=runfilelocal)

---
### 实验
Dan 给出了 k2 ctc 的基本用法和例子: [icefall](https://github.com/k2-fsa/icefall)

对照着例子，方便我们理解用法。因为 K2Ctc 和 Torch Ctc 的代码接口基本相同，所有只要极少的代码修改即可无缝对接wenet

代码可以参考 git

#### 训练 tips

刚刚开始时，由于 nnet 的结果非常不准，可能使得 DenseFsa 和 DecodeGraph 交集为空，从而造成 loss 为 inf，
为此我们采用 XXX的方案来避免早期的梯度爆炸。

### 实验结果

#### Aishell1

#### Aishell2
