---
layout: post
title: 流式语音算法工程落地框架
categories: 深度学习
description: 
keywords: 深度学习
---

九月几乎大部分精力集中在开发语音算法流式框架，工作中积累一些通用的方法和经验，
总结梳理如下，可能后续还会不断更新添加新的内容。

传送: 关于流式算法的部分 [流式语音算法总结](https://liu-feng-deeplearning.github.io/2021/08/16/%E6%B5%81%E5%BC%8F%E8%AF%AD%E9%9F%B3%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/) 

## 需求设计

这套框架设计的核心是提供一套语音算法的通用框架，通过复用通用组件，从而实现算法的快速落地。

- 满足各种输入输出。例如音频进音频出(vc)，音频进文本出(asr)，文本进音频出(tts)等。主要是满足流式算法的需求，同时也兼顾非流式的情况。
- 模型/SDK/服务尽量解耦。特别是模型和其他模块解耦，方便对接不同模型。算法开发迭代只需要在模型层面迭代即可。 
- 提供通用的设计，例如模型的内存共享，SDK和服务之间的衔接，性能压力测试等。


对于刚刚入行算法坑不久的同学，模型训得很溜，写cpp却很痛苦。希望这一套能缩短模块落地的流程，同时让更多同学把精力focus到模型和算法设计本身。


## 分层结构

整个系统按照如下分层结构设计。其中顶层模块调用底层模块，不允许跨层调用。同层直接不能互相调用。底层模块不能调用顶层模块。

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2021/2021-09-19-structure.png?raw=true" width="500" /></div>


**nnet**

- pytorch 模型推理模块的cpp封装，尽量不涉及逻辑。 
- 使用框架无关的参数（Eigen）作为nnet与外界交互类型。
- 解耦的目的是为了后期更换不同的框架 or 推理工具（如 libtorch/ONNX/tenforflow等）
- 只读不写，使用共享指针，避免水平扩展带来的内存消耗。
    
**submodule**

- 子模块的上层封装，如声码器等。在此层级实现对应逻辑，如流式结构等。
- 对输入和输出参数灵活处理，接受变长度处理。
    
**engine**

engine是子模块结构对整合，每个engine单独应对一路请求。
    
**engine_pool**
    
管理不同engine


## 共享内存的设计
（todo）

## 性能测试/压力测试
（todo）

## 服务层设计
（todo）

---



