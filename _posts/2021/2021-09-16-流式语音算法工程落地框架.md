---
layout: post
title: 流式语音算法工程落地框架
categories: 深度学习
description: 
keywords: 深度学习
---

九月几乎大部分精力集中在开发语音算法流式框架，工作中积累一些通用的方法和经验，
总结梳理如下，可能后续还会不断更新添加新的内容。

传送: 关于流式算法的部分 [流式语音算法总结](https://liu-feng-deeplearning.github.io/2021/08/16/%E6%B5%81%E5%BC%8F%E8%AF%AD%E9%9F%B3%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/) 

## 需求设计

这套框架设计的核心是提供一套语音算法的通用框架，通过复用通用组件，从而实现算法的快速落地。

- 满足各种输入输出。例如音频进音频出(vc)，音频进文本出(asr)，文本进音频出(tts)等。主要是满足流式算法的需求，同时也兼顾非流式的情况。
- 模型/SDK/服务尽量解耦。特别是模型和其他模块解耦，方便对接不同模型。算法开发迭代只需要在模型层面迭代即可。 
- 提供通用的设计，例如模型的内存共享，SDK和服务之间的衔接，性能压力测试等。


对于刚刚入行算法坑不久的同学，模型训得很溜，写cpp却很痛苦。希望这一套能缩短模块落地的流程，同时让更多同学把精力focus到模型和算法设计本身。


## 分层结构

整个系统按照如下分层结构设计。其中顶层模块调用底层模块，不允许跨层调用。同层直接不能互相调用。底层模块不能调用顶层模块。

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2021/2021-09-19-structure.png?raw=true" width="500" /></div>

以下是模块设计的细则:

**Nnet model**

神经网络的封装层，接口和 python 相同，不涉及其他的逻辑。
建议使用与框架无关的参数类型与外界交互（推荐使用 eigen)。这样做的好处是，方便对 nnet 使用的框架进行替换，
例如从 pytorch 改成 tensorflow or ONNX，外界无感知。

该模型层只读不写，使用 share_ptr 传递对象，每个模型只在 server 上产生一份内存占用（支持水平扩展）。
    
**Sub module**

该模块是具有独立功能的算法模块，例如声码器，简单的子模块只包括一个 nnet model，
复杂的可能包括数据的前后处理，多个 nnet model 的串联或并联。流式实现，大多数在此模块内完成。
为了简洁，注意控制 sub module 的对外接口。

对于流式模型，格外注意输入和输出的参数形式，建议可以接收变长度的输入类型，这样后期处理有很大的灵活性。
    
**engine**

engine 实现独立算法功能的单元。例如 AsrEngine or VcEngine，是整个项目的主体。
engine 包含多个子模块(sub module)结构。每个 eigine 对于一路独立的服务。

在此层级，可以进行完整的单路性能测试，从而评估模型的基本性能和内存占用。
    
**engine pool**

集成多个 engine 的pool 类，完成不同 engine 的创建、调用和回收。格外注意同一路服务应该在同一 engine 中完成。    

一般来说，server 上不会启动多于一个 engine_pool.

在此层级，重点测试多路服务并发运行的相关内容。

### 附录 eigen的使用技巧

个人很喜欢使用 eigen ，一个显而易见的好处是其 2D/3D 矩阵的格式很容易理解，写法简洁可读性高。
和其他数据格式相比，额外性能开销不多，因为其背后调用了 mkl，所以纯矩阵运算性能也不差。

备注：之前在某个项目中尝试计算矩阵的 exp 运算，对比了一些不同的数学库和一些网上比较 fancy 的
实现（充斥着大量不容易读懂的位运算），发现性能上并不比 eigen 更快。

一些使用上的注意要点如下：

1. 矢量化运算（SIMD），矩阵和向量的维度是16的倍数（如果使用AVX512，最好是32的倍数）。
2. 使用动态分配内存，可以避免数据存储对齐的问题（不用手工对齐）。实测动态分配内存和静态分配内存效率基本没差别。
3. lazy evaluation还是有用的，即尽量用一个长的表达式来代替短的。不过要和可读性权衡一下。
例如 T1=AX+B；T2=CT1+D 写成T2=C（AX+B）+D，让编译器进行优化。
注意，在这个例子中，对于矩阵乘法采用不同的结合方式，可能在计算次数产生巨大的差别。
4. segment和block函数效率较低，尽量减少使用。
5. 尽量避免大矩阵的拷贝。可以使用引用或指针来代替。（重要）
6. 使用A.data()来获得数据，方便和其他库混用。可以使用eigen来管理整个计算，对于个别的计算可以在调用其他库（例如mkl）
7. eigen能支持的操作比较少，int8计算的优化和稀疏矩阵的优化都不太好。因为eigen自己的设计理念是，要不做到最快要么不做。
8. eigen可以使用mkl作为内核，配合eigen一些自己的上层优化，速度可以更快一点。

## 共享内存的设计
（todo）

## 性能测试/压力测试
（todo）

## 服务层设计
（todo）

---



