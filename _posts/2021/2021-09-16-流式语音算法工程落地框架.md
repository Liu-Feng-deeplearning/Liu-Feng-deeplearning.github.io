---
layout: post
title: 流式语音算法工程落地框架
categories: 深度学习
description: 
keywords: 深度学习
---

九月几乎大部分精力集中在开发语音算法流式框架，工作中积累一些通用的方法和经验，
总结梳理如下，可能后续还会不断更新添加新的内容。

传送: 关于流式算法的部分 [流式语音算法总结](https://liu-feng-deeplearning.github.io/2021/08/16/%E6%B5%81%E5%BC%8F%E8%AF%AD%E9%9F%B3%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/) 

## 需求设计

这套框架设计的核心是实现语音算法的快速落地，特别是流式算法（当然非流式也要兼顾）。

一些设计要点：

- 满足各种输入输出。例如音频进音频出(vc)，音频进文本出(asr)，文本进音频出(tts)等。主要是
- 提供一些通用的设计，例如模型的内存共享，SDK和服务之间的衔接，性能压力测试等，这些模块对绝大多数服务是通用的。一劳永逸提供给所有的服务。
- 模型/SDK/服务尽量解耦，特别是对于新毕业的同学来说，模型训得很溜，写cpp却很痛苦。

希望缩短模块落地的流程，也让更多同学把精力focus到模型和算法设计本身。


## 分层结构

顶层调用底层模块，底层模块不能调用顶层模块。同层直接不能互相调用。

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2021/2021-09-19-structure.png?raw=true" width="800" /></div>


**nnet**

- pytorch 模型推理模块的cpp封装，尽量不涉及逻辑。 
- 使用框架无关的参数（Eigen）作为nnet与外界交互类型。
- 解耦的目的是为了后期更换不同的框架 or 推理工具（如 libtorch/ONNX/tenforflow等）
- 只读不写，使用共享指针，避免水平扩展带来的内存消耗。
    
**submodule**

- 子模块的上层封装，如声码器等。在此层级实现对应逻辑，如流式结构等。
- 对输入和输出参数灵活处理，接受变长度处理。
    
**engine**

engine是子模块结构对整合，每个engine单独应对一路请求。
    
**engine_pool**
    
管理不同engine


## 共享内存的设计
（todo）

## 性能测试/压力测试
（todo）

## 服务层设计
（todo）

---



