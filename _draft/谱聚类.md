# 谱聚类

谱聚类很有效，这几乎是所有做speaker-diarization人的共识了。
但为什么谱聚类有效，比k-means好在哪里？

### 谱聚类简介

关于谱聚类，看这一篇文章就够了。https://arxiv.org/pdf/0711.0189.pdf
里面有很多公式/定理/推导，本节总结一些里面关键精华的部分。

也有一些不错的中文链接

- https://zhuanlan.zhihu.com/p/29849122
- https://www.cnblogs.com/pinard/p/6221564.html

核心算法流程：
<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2021/2021-11-07-spectral-cluster-3.png?raw=true" width="360" /></div>

核心点：
- 问题的构建，使用图结构表述问题，构建相似矩阵并提出最优化函数
- 引入Graph-Laplace Matrix，使用线性代数中的矩阵分析方法，将优化问题转换为求解矩阵特征值/特征向量的问题，从而对原始问题进行了降维度求解

另外一些比较有意思的点


### advantage

为什么谱聚类有效？

传统的 kmeans 算法是基于point的数据驱动算法，每次迭代考虑的都是单个样本和其他样本的距离。
而谱聚类本质是一种图算法，考虑的是集合之间的距离。因此，谱聚类相当于从更"全局"的角度来考虑问题。

例如下图所示的一些数据样本：
图片来自于 https://www.quora.com/What-are-the-advantages-of-spectral-clustering-over-k-means-clustering

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2021/2021-11-07-spectral-cluster.png?raw=true" width="360" /></div>

这些都是 k-means 算法很难处理的case。选择合适的核函数，可能会对case1/3/5处理得更好，
但选择核函数本身就是一件很困难的事情。究其原因，就是k-means只考虑临近点，并没有把同一个cluster当成一个整体导致的。
因此出现下列结果可能也不足为奇了。

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2021/2021-11-07-spectral-cluster-2.png?raw=true" width="360" /></div>

### 总结

spectral 从另一个角度来讲，也可以认为是一种embedding，毕竟后面还是接了一个普通的 cluster 算法。

算法实现上，直接在sklearn中调库+简单调参即可，之前在追一时候工程实现了对应的cpp代码，也并不复杂。但是算法背后的原理，以及图论对应思想，可能蕴含着更多有意思和启发性的东西。