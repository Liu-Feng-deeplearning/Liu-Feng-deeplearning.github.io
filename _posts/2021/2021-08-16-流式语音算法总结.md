---
layout: post
title: 流式语音算法总结
categories: 深度学习
description: 
keywords: 深度学习
---

语音算法中，流式模型是一个重要的应用场景。


流式场景是语音中特有的一类问题。和 vc 以及 nlp 问题不同，语音输入 or 输出具有极强的时序性，
音频是以 chunk 形式发送和接收的。因此，我们不需要等待所有 chunk 发送完毕，可以边发送边处理，
从而获得更好的实时性能和用户体验。

## 语音算法中的流式场景

这是几个常见的流式语音任务。

- VC(voice conversation), 音频进音频出。每次输入音频片段，输出转换后的音频。 
- ASR，音频进文本出。每次输入音频片段，输出该音频片段对应文本（可以为空）。
当所有音频输入结束时（输入对应结束标记），对已经输出所有文本进行重排or整合，得到最终输出文本。 
- TTS，文本进音频出。输入一段文本，依次输出每段生成音频，边播放边生成下一段音频。
- vad or AED，音频进标签出，每次输入音频片段，输出帧对应标签。

## 流式算法的平均指标

流式语音算法实现的前提是 rtf<1.0 即处理1s音频时所用时间小于1s，事实上由于还要考虑网络延时，rtf应该远小于1。
rtf满足要求的情况下，后续处理不会阻塞，在此前提下，我们通常使用如下两个指标来评估流式系统的性能。

- 首片延时，系统处理第一个音频片段时，从接收数据到返回结果所用的时间。该指标反映了流式系统下，
用户获得反馈的最小用时，是直观体现用户体验的核心指标。
- 每路服务cpu占用率，该指标反映了系统运行时对资源的占用情况。在多路并发场景下，该每路服务使用更少的cpu，
意味着相同资源下可以处理更多服务请求，从而节约了服务器成本。

在 asr 任务中，因为最后会对所有文本进行重排，因此我们有一个额外对测试指标：
- 尾片延时，服务接收到音频结束标志符到返回最终正确结果的延时，该指标意味着流式系统下拿到最准确asr结果所用延时，
也是反应asr系统性能的核心指标。在某些应用场景（例如客服对话系统）下，尾片延时是比首片延时更重要的指标参数。

## 流式算法的实现

如果一个算法是流式的，且和非流式在数值上完全相同，则需要满足(这里+表示concat的意思)

```math
f(chunk1+chunk2+chunk3...) = f(chunk1) + f(chunk2) + f(chunk3) ...
```

这样边可以对每个输入片段分别计算再拼接，从而达到流式效果。

对于绝大多数模型来讲，满足如下条件，只需进行少量改动，即可满足流式需求。
1. 模型不使用未来时间的数据（或者只使用有限未来时间的数据）
2. 模型不适用 local 统计值，例如不适用当前特征的时间平均特征信息。

### CNN 层
- 相对更复杂一些，需要格外小心 chunk 边界情况的处理。可以类似 wenet 处理逻辑，使用cache的方式。也可以类似 online-hifigan 的实现，手动处理拼接处的采样点。
- 对于输入输出不等长的情况，可以考虑使用valid模式的卷积核，在边界处理时更简洁。可以参考wenet中subsampling 模块的实现。
- 大多数情况下，会在边缘处有冗余计算。chunk不太小的情况下，影响有限。例如下图，图片来源于[wenet](https://github.com/wenet-e2e/wenet/blob/main/docs/images/subsampling_overalp.gif)

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2021/2021-08-16-subsampling_overalp.gif?raw=true" width="500" /></div>

### Rnn 层
- 如果有流式需求，一开始就不要用双向结构。
- 对于单向 rnn，如 lstm ，只需每次计算保存隐状态值在输出给下个计算 chunk 即可。

### 不同模型的组合

可以设计若干个 memory， 对不同模型使用不同的处理方案。例如这样实现

```text
# for offline
input = ...
x1 = model_a(input)
x2 = model_b(x1)
output = model_c(x2)

# for online
input_chunk = ...
input.append(input_chunk)  # add more data for queue of inp
x1_chunk = model_a(input[p_inp, p_inp + len_inp])  # compute chunk of inp
x1_valid = x1_chunk[0]
x1.append(x1_valid)  # add generate data for queue of x1
x2_chunk = model_b(x1[p_x1, p_x1 + len_x1])  #  compute chunk of x1
... 

```

## 流式语音特征 (待补充)

### wav acceptor

### mel-spec

### pitch or energy
 
---

设计流式算法，核心还是对效果/延迟/计算资源的平衡，需要更多在一开始就进行整体设计。