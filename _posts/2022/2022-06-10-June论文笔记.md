---
layout: post
title: 2022June论文笔记
categories: 读书笔记
description: 
keywords: 读书笔记
---

2022年10月 论文/读书笔记

## TTS 

#### A: [Learning Latent Rep- resentations for Style Control and Transfer in End-to-end Speech Synthesis](https://arxiv.org/pdf/1812.04342.pdf)

微软使用 vae 对 tts 做风格建模的文章，结构上和之前 g 的 gst 有点像，从 target audio 中提取固定长度 vec 作为 latent variables **z**, 
然后推理的时候，从 ref audio 中提取。

为了防止 KL collapse，采取了kl-loss 系数从小到大的策略，防止开始阶段，之间把 z 采成正态分布从而啥都没学到。
除此，一些模型结构和参数也可以参考借鉴。vae 的一个核心 encoder，就是把可变长度的向量/矩阵，
转成一个固定长度的向量。

基本这个结构就是和我自己在 vc 中使用的相同。


#### B: [Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech]

CVAE 的文章，

### VC

#### A: [Enriching Source Style Transfer in Recognition-Synthesis based Non-Parallel Voice Conversion](https://arxiv.org/pdf/2106.08741.pdf)

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2022/2022-06-20-paper-img-01.png?raw=true" width="600" /></div>

西工大谢老师他们的论文，之前读过，拿出来重读了一下发现有几个之前没注意到的点。
论文核心在于讲 prosody 的建模方式，包括显示的特征（energy and pitch）和隐式的特征，reference-encoder and vae latent embedding，
以及 SA-WA 的编码器结构。explicit 特征以及 SA-WA 结构，和我自己之前实现差别不大，主要是 VAE 和 ref-encoder 两部分，有一些细节：

- 使用 bn 作为 ref-enc 的输入，而不是 mel 谱，这里会默认 bn 里包括里prosody的信息，以及比较好的去除里 spk 信息
- 使用 vae 提取 embed 之后，过一个 speaker-classifier 生成 posterior，并对此进行优化。
使用 adv-loss/ce-loss 交替进行训练。（这个地方的设计得精巧）
- 三个方案生成的 prosody 特征进行融合。
 
<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2022/2022-06-20-paper-img-02.png?raw=true" width="200" /></div>

论文里有一个地方图文矛盾，可能是笔误，prosody 的多特征融合应该是 concat，而不是 addition？

刚好最近正在复现类似的结构，可以到时一并看下对比结果。

## ASR

#### A:[Toward Zero Oracle Word Error Rate on the Switchboard Benchmark](https://arxiv.org/pdf/2206.06192.pdf)

Asr 论文届的一股清流，话说 mod9 是一个做语音的服务公司吗？？

一篇讲 asr benchmark 的论文

- 讲了一些 asr 标注导致数据的出入，例如文本正则化，重复词语的过滤，一些同音/同义词替换之类的，
这些过滤/正则会使得asr测试指标升高。
- 对多个asr 系统指标做了评测，罗列结果。 

大体上做的工作类似 SpeechIO，asr 的结果评测其实并不简单，里面有很多琐碎的细节都会对指标造成重大影响。
（是否从另一方面也说明了大多数论文的 asr 指标以及benchmark里面"水分"较大，不可轻信？？）


## CSI

A: [BYTECOVER: COVER SONG IDENTIFICATION VIA MULTI-LOSS TRAINING](https://arxiv.org/pdf/2010.14022.pdf)

字节关于 csi 的论文，用 表征学习的想法来做翻唱检索，而不是多分类的任务。

提出了一个 resnet-ibn 的结构 以及对应的 loss，同时兼顾类内和类间的距离。

比较好的是，论文介绍给了一些开源数据集，对这个领域的 入门者 还比较有帮助。

---


## To Read List

### [Voice Conversion Based Speaker Normalization for Acoustic Unit Discovery](https://arxiv.org/pdf/2105.01786.pdf)
### [A Unified Cascaded Encoder ASR Model for Dynamic Model Sizes](https://arxiv.org/pdf/2204.06164.pdf)
### [Unified Speech-Text Pre-training for Speech Translation and Recognition](https://arxiv.org/pdf/2204.05409.pdf)
### [VoiceFixer: A Unified Framework for High-Fidelity Speech Restoration]()
[Accented Speech Recognition: Benchmarking, Pre-training, and Diverse Data](https://arxiv.org/pdf/2205.08014.pdf)

A: [FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis](https://arxiv.org/pdf/2204.09934.pdf)

