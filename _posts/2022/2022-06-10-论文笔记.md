---
layout: post
title: 2022-06 论文笔记
categories: 语音信号处理
description: 
keywords: 语音信号处理
---

陆续更新中

## TTS 

### VC

#### A: [Enriching Source Style Transfer in Recognition-Synthesis based Non-Parallel Voice Conversion](https://arxiv.org/pdf/2106.08741.pdf)

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2022/2022-06-20-paper-img-01.png?raw=true" width="600" /></div>

西工大谢老师他们的论文，之前读过，拿出来重读了一下发现有几个之前没注意到的点。
论文核心在于讲 prosody 的建模方式，包括显示的特征（energy and pitch）和隐式的特征，reference-encoder and vae latent embedding，
以及 SA-WA 的编码器结构。explicit 特征以及 SA-WA 结构，和我自己之前实现差别不大，主要是 VAE 和 ref-encoder 两部分，有一些细节：

- 使用 bn 作为 ref-enc 的输入，而不是 mel 谱，这里会默认 bn 里包括里prosody的信息，以及比较好的去除里 spk 信息
- 使用 vae 提取 embed 之后，过一个 speaker-classifier 生成 posterior，并对此进行优化。
使用 adv-loss/ce-loss 交替进行训练。（这个地方的设计得精巧）
- 三个方案生成的 prosody 特征进行融合。
 
<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2022/2022-06-20-paper-img-02.png?raw=true" width="200" /></div>

论文里有一个地方图文矛盾，可能是笔误，prosody 的多特征融合应该是 concat，而不是 addition？

刚好最近正在复现类似的结构，可以到时一并看下对比结果。

## ASR

## ST

## CSI

A: [BYTECOVER: COVER SONG IDENTIFICATION VIA MULTI-LOSS TRAINING](https://arxiv.org/pdf/2010.14022.pdf)

字节关于 csi 的论文，用 表征学习的想法来做翻唱检索，而不是多分类的任务。

提出了一个 resnet-ibn 的结构 以及对应的 loss，同时兼顾类内和类间的距离。

比较好的是，论文介绍给了一些开源数据集，对这个领域的 入门者 还比较有帮助。

---


## To Read List

### [Voice Conversion Based Speaker Normalization for Acoustic Unit Discovery](https://arxiv.org/pdf/2105.01786.pdf)
### [A Unified Cascaded Encoder ASR Model for Dynamic Model Sizes](https://arxiv.org/pdf/2204.06164.pdf)
### [Unified Speech-Text Pre-training for Speech Translation and Recognition](https://arxiv.org/pdf/2204.05409.pdf)
### [VoiceFixer: A Unified Framework for High-Fidelity Speech Restoration]()
[Accented Speech Recognition: Benchmarking, Pre-training, and Diverse Data](https://arxiv.org/pdf/2205.08014.pdf)

A: [FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis](https://arxiv.org/pdf/2204.09934.pdf)

B: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech