---
layout: post
title: 2022-05-10 论文笔记
categories: 语音信号处理
description: 
keywords: 语音信号处理
---

陆续更新中

## TTS and Vc

### [NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality](https://arxiv.org/pdf/2205.04421.pdf)

微软关于 tts 最新论文，使用 vae 的主体架构

核心的几个优势:
- 解决训练/推理之间的 mismatch
- 减缓 one-to-many 的问题
- 提升 representation 的表现能力

整个tts的系统的特点:
- 非自回归结构，推理速度快
- 纯端到端系统，非串联
- 可微分结构 (改进了不可微分的 priority encoder 和 durator)
- 更好的性能 (这个似乎讲得有点牵强) 

结构简图:

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2022/2022-05-10-paper-img-01.png?raw=true" width="600" /></div>

整体结构是一个标准的 vae 结构

wave: x, phoneme: y, representation: z

```math
x: -> z -> x`
z = q(z|x) 
y:-> z 
z` = p(z`|y)
loss = rec_loss(x`, x) + KL(z`||z)  
```
other trick: 
- 使用带有 mask 机制训练的 encoder，(类似bert？), 使用 adjacent phoneme 作为特征，
本质解决文本维度过高的问题
- 可微分的 durator，soft dynamic DTW for KL
- 基于 flow 的 prior/posterior 转换器，**这里不是直接对p和q求kl距离**，而是对转换后的特征求。
- 使用 vae 结果作为 decoder 的 attention。

---

### [SyntaSpeech: Syntax-Aware Generative Adversarial Text-to-Speech](https://arxiv.org/pdf/2204.11792.pdf)

浙大 tts 前端的工作

使用 Dependency Parsing Tree 来对文本前端进行分析，并提取对应特征。

---

### [ONE-SHOT VOICE CONVERSION FOR STYLE TRANSFER BASED ON SPEAKER ADAPTATION](https://arxiv.org/pdf/2111.12277.pdf)

西工大 one-shot vc

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2022/2022-05-10-paper-img-02.png?raw=true" width="600" /></div>

- speaker normalization，核心还是去除 speaker 信息，但是没怎么详细讲
- finetune 的时候对参数使用了 weight regularization，让参数不要偏移太多，来应对 one-shot 的情况，可能有用，待尝试？
- source style transfer 跟之前的论文差别不大
- 3-stage 训练

## ASR

### [E2E Segmenter: Joint Segmenting and Decoding for Long-Form ASR](https://arxiv.org/pdf/2204.10749.pdf)

google Sad 结合 rnnt 的方案

- 使用音频和文本作为输入
- 使用规则来生成数据 heuristic-based weak supervision approach 

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2022/2022-05-10-paper-img-03.png?raw=true" width="400" /></div>

---
## ToRead List


### [Why does Self-Supervised Learning for Speech Recognition Benefit Speaker Recognition](https://arxiv.org/pdf/2204.12765.pdf)

### [Mask scalar prediction for improving robust automatic speech recognition](https://arxiv.org/pdf/2204.12768.pdf)

### [Voice Conversion Based Speaker Normalization for Acoustic Unit Discovery](https://arxiv.org/pdf/2105.01786.pdf)
### []()
### []()
### []()
### []()
### []()

