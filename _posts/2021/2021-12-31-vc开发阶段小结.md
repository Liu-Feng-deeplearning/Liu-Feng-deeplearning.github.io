---
layout: post
title: vc算法阶段小结
categories: 语音信号处理
description: 
keywords: 语音信号处理
---


2021年，如果说总结自己在算法上的核心探索，可能 vc 就是其中重要一环。
希望能有一篇文章，讲下自己当时做的一些工作和经验，虽然可能并不完美，但毕竟做了八个月，还是应该有一个总结。


### 算法初探

最开始接触 vc 是在21年4月的时候，大师说要做一套 vc 系统，我就在很短的时间内攒了一套出来。
当时，采用了ctc(sub=4)+ encoder(cbhg)+ attention + decoder + hifigan 的方案。
因为都是我们已经有的模块，所以虽然流程比较长，但搭建并不费事。
对于这样一个快速验证方案，我们还是经过了一些思考和推敲。
因为采用 asr-tts 系统 + 单音色使用场景，音色相似度基本有保障，流畅度和可懂度预期可以追平tts的目前效果。
这样 vc 面临的挑战大体上就只剩下了鲁棒性。
当时花了一点时间来测试各种各样的 case，发现其实整体效果还可以，这个结果给了我们很多信心，
觉得要把 vc 这个事情持续的做下去。

当时，badcase 高发区是快语速和带躁场景这两块。在当时的系统架构上，我们又做了一些类似速度增强等小的改进，
来规避这两方面的问题。同时，给系统增加了 vad 等前端模块，让整个 vc 更像一个"系统"，而非"模型"。

算法 demo 有了之后，我和建坤一起完成了体验 demo 页面，可以实时进行音色转换，
并同步上线了两个音色：zhiling and wukong。这时 vc 看上去终于有了个产品的样子。
后来去和搜狗线上的 vc 效果对比(他们刚好也有这两个音色)，
总体上感觉旗鼓相当，他们的鲁棒性更好一点，但我们相似度更高点。但遇到比较难的case，可能他们还是出错的几率更少一点。

一时间信心满满，感觉再优化一下便可以上线，但没想到开始即是巅峰，好运到此戛然而止了。

### 核心算法开发经验与教训

上线前我们遇到了两个主要问题，不能流式/情感表达不好。
看上去前者只要用支持chunk推理的网络单元，后者把pitch特征加进去就解决了，似乎并不难。

但进展比想象的更不顺利。

第一阶段的算法验证为了更快出结果，有几个地方处理的很草率。

首先是 speaker-embedding 一直没有奏效。
可视化了 deyi 之前提供脚本抽取结果，不同说话人聚类效应明显，但使用起来却不是很理想。
在 baseline 上加上 spk-emb，总是会带来负面效果。
当时倾向于 spk-emb 使用方式待商榷，以及代码本身可能哪里写的有问题。
这个问题直到很久以后才解决掉，其实是多说话人数据丰富度不够导致的。

其次，ce-based or ctc-based ppg? 这个问题一直贯穿在整个 vc 过程中。
和欣陶一起验证了很久，一直没什么头绪。ce 粒度更细，可以更好建模发音特征，也是比较主流的方案，但我们可能一直没处理好。
当时，我自己做了一个简单的版本(torch-tdnnf)，复现了剑涛之前的版本(tdnn)，找志平帮忙训练了kaldi的版本(cnn-tdnn)，
还有一个腾讯ai-lab的版本(但受限与时间并没有试)，都没有取得更好的效果。
主要表现在鲁棒性不理想，好的更好，差的更差了。
无奈我们最终选择了 ctc 的方案，还是先保证鲁棒性。
后来在创新项目评选中，大家提出了让vc能满足多方言和外文的需求，我们又发现之前的baseline效果很不行。
其表现是在发其他语音时，还带有浓重的普通话的腔调。
当时的方案下，source 发音不清楚的时候，前者会把发音不清楚的字音，转换成相对标准的普通话发音。
之前我一直觉得是个优点，但在方言转换任务里变成了缺点。
后来欣陶发现ctc下令subsample=1是更好的方案，后面我们也在这方面进行了一些尝试。
直到如今，依然觉得 ppg/content-embedding 这块感觉做得还是比较粗糙，后续会把这块抽成一个单独的项目来做。

关于 emotion。之前的方案有个很大的缺点，对于不同语调相同内容的source-audio，
输出基本没有差异性，这显然和 vc 本来的出发点相违背。vc 还是应该在语义本身传输完整性之外，包含更多节奏/预期/音色相关的内容。
尝试了一些基于 pitch/f0 特征的方法，均不奏效。发现这个问题真的很难，貌似不是随便搞一下就能搞定的。
pitch 在 source 到 target 的偏移过程中，总是会带来性能上的损失。另外，pitch 对流式场景天然不友好，也是比较头疼麻烦对问题。
虽然目前也有不少论文提到了一些解决方案，我也大体上复现一些(例如西工大+爱奇艺的那篇)，但距离实际使用还差的非常远。
无奈这个问题被搁置了。

关于流式模型，其实主要问题处在 ppg 的模型训练上，使用 wenet-transformer 训练流式模型其实是可行的。
毕竟 asr 组在这方面已经取得到很不错效果。但莫名其妙的，因为一些细节没处理好在这方面还是走了不少弯路。
同时，整个 convert 模型，工程化被拆成了多个子模型分别实现，非常之丑陋，且代码量巨大。
这里也是一个比较糟糕的工作，当时没有做好，后续可能会看看补救改正一下。

### 工程优化与实现

工程层面，借着 vc 项目，着手搭建了更为通用的 HSS (Huya Streaming Speech) 平台，完善了整个流式的语音框架。
流式语音平台框架和工程相关内容，可能大多已经在前面文章中总结了，这里不赘述。

聊下这个带来的收获吧，可能最大收获就是在大量的 c++ 开发下，对语言更熟悉了。
现在不会像之前那么发怵与写 c++。虽然 c++ 博大精深，远远谈不上精通，起码不会成为短板。
其次，对怎样落地一个工程项目也会了解熟悉更多，也可以更好的指导自己完成更好的算法开发。
例如，现在无论什么项目，都会尽量遵循音频进-音频出的模式，所有逻辑尽量都写在模型里，这样对工程实现的简便性有极大的帮助。
第三，就是了解了一些和服务层相关的知识，起码 websocket 开发有了一个入门级经验，也可以独立搭一些可用的服务出来。

和纯算法探索不同，工程层面还是有一些实打实的经验和成果积累下来，也算是2021下半场一个不错的成果吧。

### 反思与总结

1. 实验方法论的问题，过早的追求大模型or大数据，在无谓的实验上花费精力过多。
2. 对整体路线选择和把控还不太成熟。其实，可以先选择把离线方案做好，然后再搞在线方案是更稳妥的选择。
3. 很多关键的路线上，选择有待商榷。例如早点开始transformer，以及不要执迷于ctc-based ppg。
但这个更多和对算法的认知以及和对整个领域的scope有关，还需要慢慢积累。
4. 需要及时总结，代码不断重构和抽象，及时总结技术文档。这点也是之前几年工作中比较欠缺的点，可能今年才会逐渐好些。

### 未来计划-关于 vc

vc 涉及到相对底层的模块，感觉还是需要把这些的基础打牢。罗列几个 2022 上半年的 todo-list 在这里

- 一套更好的 ppg 提取器，一定还是帧级别的方案。希望能独立于 vc 做成一个更加通用的模块，支持双语。
- 基于 transformer 的轻量级 mel-convert model
- emotion 的问题。
- 2022 VCC 

