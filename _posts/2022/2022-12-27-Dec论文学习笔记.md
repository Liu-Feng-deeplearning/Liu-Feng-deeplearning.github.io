---
layout: post
title: 2022 Dec 论文笔记
categories: 读书笔记
description: 
keywords: 读书笔记
---
2022年12月 论文/读书笔记



## [SoundStream: An End-to-End Neural Audio Codec](https://arxiv.org/pdf/2107.03312.pdf)

Google 的神经网络codec 论文

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2022/2022-12-27-papers-codec.png?raw=true" width="800" /></div>

几个要点: 
1. 神经网络声码器，纯端到端的方案。enc + quantizer + decoder 的 pipeline
2. residual quantizer, and 自适应bitrate（同一模型应对不同的比特率）
3. 高效的 encoder，可以用来代替 mel 
4. 更好的效果
5. 支持流式与低延时
6. 压缩和增强同时完成

## [AudioLM: a Language Modeling Approach toAudio Generation](https://arxiv.org/pdf/2209.03143.pdf)

<div style="text-align: center"><img src="https://github.com/Liu-Feng-deeplearning/Liu-Feng-deeplearning.github.io/blob/master/images/posts/2022/2022-12-28-papers-audioLM.png?raw=true" width="800" /></div>

Google 关于语音领域-预训练模型的论文

[论文对应demo页面](https://google-research.github.io/seanet/audiolm/examples/)

很有意思的想法，把连续的信号量，通过一个神经网络获得 semantic token
（我们一般都认为语音信号是稀疏数据，高采样率下，存在过多的冗余表示。
这篇论文的做法，相当于是稀疏数据的稠密表达。和 ASR 之类的做法相比，他又没有那么直接，也没有那么抽象，这个过程中可能还保留了一些语义之外的信息。）
通过一个 encoder/decoder 结构，完成 signal->token 两个方向的转换。decoder 部分相当于一个声码器，只是这里对应的特征从 mel 谱换成了之前提到的 semantic-token。
然后对于提取的 token，他可以用一个 Mask-based model 来进行预测（类似bert，虽然我觉得可能使用类似 gpt 的模型架构会更好一点）。这样两部分相结合，AudioLM 可以完成对 语音片段的预测。
类似与文本预测+TTS，但这里不仅语义内容是连续可懂的，同时语气语调之类的副语言信息也能够很好的建模。

