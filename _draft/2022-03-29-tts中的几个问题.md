
# TTS 中的过度平滑问题-VAE 与 GAN

随手记录一些最近思考得 tts/vc 中表现力相关的问题点。

虽然可能不一定对，但梳理对后续还是有所启发。

### 过度平滑

**什么是过度平滑？(OverSmooth)**

在 tts 中经常会出现现象: 生成音频的风格表现力变弱，生成音频感觉会更平淡，从而会丧失一些
发音人的特点。特别是在 emotional tts 这个细分领域，可能出现的概率会更频繁。

**出现过度平滑的原因是什么？**

对于大多数 tts  系统，训练的核心都是 使用 MSE/MAE 来最小化重建损失(reconstruction loss)
来获得自然度和音色相似度的最优。即对于训练数据 $x, y$代表文本和音频，训练模型 &y` = f(x), s,t, loss(x, y) &

但是，和文本数据而言，音频数据其实是更为稠密的数据表现形式。
- 相同的文本信息，可能会存在不同的音频，这些音频对应的波形 y可能数据分布差异很大
- 文本信息只是音频 content 的高度抽象的表达，除此之后，还有音色/duration/prosody等其他
音素会影响整个音频。

因此如果观察数据分布，往往会存在同一个 x 对应多个 y 的情况。
即使我们通过合适的筛选数据保证 utterance 的程度不存在，但 level 层面依然有。
毕竟 text 里一定会有大量的音素标签反复出现。

假如对于某个x，这里以 ang1 为例（汉语中张的韵母），会存在多个y，如果画出这些y的分布，
大概率是概率分布。如果是 mse 方法训练，大概率x 会对应到这些 y 分布的平均值上。
这便是过度平滑造成损失的来源。

对于传统的 merlin 方法，首先训练 duration model 后，将每个音素对应到对应的帧上面，因此
过度平滑出现非常频繁。但是对于tacotron-based 方法，存在 encoder 将 x 转成 enc-embed。
encoder(cbhg/transformer) 一般是接收整个文本作为输入，通过全局 attention 和 双向 rnn,
这样即使对应相同音素的相邻帧，也会有不同的特征表示。再加上自回归的decoder，可能会更大程度上规避这样的问题。

但是，相似的文本依然有可能得到相似的 embed。


**解决方案**

顺便推荐一篇浙大的相关论文，对比了不同方法在过度平滑这个问题上的表现。
分析和实验都比较有启发。[Revisiting Over-Smoothness in Text to Speech](https://arxiv.org/pdf/2202.13066.pdf)

问题产生的原因清晰了，解决方案也顺利成章了：
1. 使用更多 variance data
2. 模型层面的改进

之前我们提到过 x - y 容易出现 一对多的训练情况，我们可以通过扩展数据，增加 x 的维度，从而训练
变成了 x|x1 -》y ，从而简化了y的数据分布，进而解决问题。

例如 tacotron 和 merlin 相比，一个重大的进步就是，使用 nnet-encoder 提取 embedding，这个过程中，
每帧 embed 不仅和当前音素有关，还和之前/之后的音素有关。某种程度上变相的使用了更多信息。

还有一些更为先进的方案，采用了dur/pitch/energy 的特征，本质上都是"细化"了x, 从而简化 了y
的分布。

除此之外，还有一些模型层面的优化方案，例如改进损失函数和结构。
前面我们提到过的自回归方案，就是一个不错的选项，当然他自己还有一些别的问题，例如性能。
使用 Flow/VAE/GAN 之类的方案来做。


题外话: 从客服 tts 开始接触这个领域，可能开始接触的问题比较简单，不太涉及惊喜粒度的表现力问题，
更多集中在可懂度/自然度和相似性上，关注得比较少。

### VAE 

vae(variable encoder) 是目前生成问题中大火的模型。看了一些文章和介绍，
但感觉有点还是不够清晰。

vae 的核心是认为 encoder 由很多个隐变量组成，每个隐变量分布虽然未知，
但总是可以用多个高斯分布的和近似模拟。

例如从 数字 label -》 图片（minst经典识别的反问题）
可能除了 content以外，图片中还包括了 style/position/灰度等其他的信息。

训练流程：

推理流程：

这些信息 都用隐变量 来表示，但可能会。

另一个缺点是可解释性。

**vae-vc**      

可能并不是很适合。

但是 对于 vc 而言，


### GAN

GAN 也是目前比较主流的生成方案。GAN-based vocoder 目前已经成为了主流声码器。
和其他方法相比，gan 主要可以大幅度提升生成样本的清晰度（特别是针对 non-auto gressive）。

但是 gan 面临的一个理论的缺陷是 mode collapse

**mode collapse**

Mode collapse 问题：如果 x -》y，也是一个 1对多的问题，gan 会随机的收敛到其中一个值上
（不是平均值），虽然会更好一点，但也会丢掉很多其他可能的情况。

然而比较幸运的是，对于声码器来说，x（mel）本身也是稠密的，几乎是一个1对1问题，
这和图片生成/tts生成有很大的区别。因此 Mode collapse 非常不严重。信号值虽然更稠密，但mel
几乎包括了所有但信息。

除此之外，还有一类方法是在 mel 谱层面使用 Gan，从这个角度看，似乎必要性不大。
